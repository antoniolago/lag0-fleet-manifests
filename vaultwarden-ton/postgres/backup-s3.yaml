apiVersion: batch/v1
kind: CronJob
metadata:
  name: db-dump-s3-cronjob
spec:
  schedule: "0 0 * * *"
  jobTemplate:
    spec:
      template:
        spec:
          initContainers:
            - name: pg-dump
              image: postgres:16-alpine
              env:
                - name: DB_HOST
                  value: "vaultwarden-postgres.vaultwarden.svc.cluster.local"
                - name: DB_PORT
                  value: "5432"
                - name: DB_USER
                  value: "vaultwarden"
                - name: DB_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: vaultwarden-secrets
                      key: POSTGRES_PASSWORD
                - name: DB_NAME
                  value: "vaultwarden"
              command:
                - /bin/sh
                - -c
                - |
                  set -e
                  export PGPASSWORD=$DB_PASSWORD
                  DUMP_FILE=${DB_NAME}_$(date +%Y%m%d%H%M).sql
                  pg_dump -h $DB_HOST -p $DB_PORT -U $DB_USER $DB_NAME > /shared/$DUMP_FILE
                  echo $DUMP_FILE > /shared/backup_file_name.txt
                  echo "Database dump created at $DUMP_FILE"
              volumeMounts:
                - name: shared-storage
                  mountPath: /shared
          containers:
            - name: upload-dump-to-s3
              image: d3fk/s3cmd
              env:
                - name: DB_NAME
                  value: "vaultwarden"
                - name: AWS_ACCESS_KEY_ID
                  valueFrom:
                    secretKeyRef:
                      name: rustfs-credentials
                      key: access-key
                - name: AWS_SECRET_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      name: rustfs-credentials
                      key: secret-key
                - name: S3_BUCKET
                  value: "backups"
                - name: S3_PATH
                  value: "vaultwarden/daily"
                - name: S3_ENDPOINT
                  value: "https://s3.lag0.com.br"
                - name: S3_REGION
                  value: "ton-cluster"
              command:
                - /bin/sh
                - -c
                - |
                  set -e
                  BACKUP_FILE=$(cat /shared/backup_file_name.txt)
                  # Upload the dump to S3
                  s3cmd --host-bucket=$S3_REGION/$S3_BUCKET --region=$S3_REGION --host=$S3_ENDPOINT put -d -v --ssl /shared/$BACKUP_FILE s3://$S3_BUCKET/$S3_PATH/$BACKUP_FILE
                  
                  echo "Backup and upload completed successfully!"
              volumeMounts:
                - name: shared-storage
                  mountPath: /shared
          restartPolicy: OnFailure
          volumes:
            - name: shared-storage
              emptyDir: {}
